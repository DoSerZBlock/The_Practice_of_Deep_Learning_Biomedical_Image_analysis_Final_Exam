{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": 1,
            "id": "4d0b34d6",
            "metadata": {
                "colab": {
                    "base_uri": "https://localhost:8080/"
                },
                "executionInfo": {
                    "elapsed": 16592,
                    "status": "ok",
                    "timestamp": 1749049758690,
                    "user": {
                        "displayName": "毒蛇DoSer",
                        "userId": "08540475497554539948"
                    },
                    "user_tz": -480
                },
                "id": "4d0b34d6",
                "outputId": "da11e78c-987a-4121-c91f-3d801621f47a"
            },
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Downloading from https://www.kaggle.com/api/v1/datasets/download/mrmaazoo/breast-ultrasound-classification?dataset_version_number=1...\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "100%|██████████| 188M/188M [00:01<00:00, 108MB/s]"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Extracting files...\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Path to dataset files: /root/.cache/kagglehub/datasets/mrmaazoo/breast-ultrasound-classification/versions/1\n"
                    ]
                }
            ],
            "source": [
                "import kagglehub\n",
                "\n",
                "# Download latest version\n",
                "path = kagglehub.dataset_download(\n",
                "    \"mrmaazoo/breast-ultrasound-classification\",\n",
                ")\n",
                "\n",
                "print(\"Path to dataset files:\", path)\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "id": "b4032639",
            "metadata": {
                "executionInfo": {
                    "elapsed": 14,
                    "status": "ok",
                    "timestamp": 1749049758708,
                    "user": {
                        "displayName": "毒蛇DoSer",
                        "userId": "08540475497554539948"
                    },
                    "user_tz": -480
                },
                "id": "b4032639"
            },
            "outputs": [],
            "source": [
                "import matplotlib.pyplot as plt\n",
                "\n",
                "# ========== 7. 視覺化 ==========\n",
                "def plot_history(history, title_suffix=\"\"):\n",
                "    plt.figure()\n",
                "    plt.plot(history.history[\"loss\"], label=\"train\")\n",
                "    plt.plot(history.history[\"val_loss\"], label=\"val\")\n",
                "    plt.xlabel(\"Epoch\")\n",
                "    plt.ylabel(\"Loss\")\n",
                "    plt.title(f\"Loss {title_suffix}\")\n",
                "    plt.legend()\n",
                "    plt.show()\n",
                "\n",
                "    plt.figure()\n",
                "    plt.plot(history.history[\"accuracy\"], label=\"train\")\n",
                "    plt.plot(history.history[\"val_accuracy\"], label=\"val\")\n",
                "    plt.xlabel(\"Epoch\")\n",
                "    plt.ylabel(\"Accuracy\")\n",
                "    plt.title(f\"Accuracy {title_suffix}\")\n",
                "    plt.legend()\n",
                "    plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "id": "1d37cd01",
            "metadata": {
                "executionInfo": {
                    "elapsed": 8249,
                    "status": "ok",
                    "timestamp": 1749049766960,
                    "user": {
                        "displayName": "毒蛇DoSer",
                        "userId": "08540475497554539948"
                    },
                    "user_tz": -480
                },
                "id": "1d37cd01"
            },
            "outputs": [],
            "source": [
                "import tensorflow as tf\n",
                "from tensorflow.keras import layers\n",
                "from tensorflow.keras.applications.efficientnet import (\n",
                "    EfficientNetB0, preprocess_input,\n",
                ")\n",
                "from sklearn.model_selection import train_test_split\n",
                "from sklearn.utils import class_weight\n",
                "import numpy as np\n",
                "from pathlib import Path\n",
                "\n",
                "# ========== 0. 基本設定 ==========\n",
                "DATA_DIR   = Path(path) / \"BUSI_Corrected\"   # <-- 把 path 換成你的資料根目錄\n",
                "IMG_SIZE   = (256, 256)                      # ★ 改成 256 × 256\n",
                "BATCH_SIZE = 32\n",
                "AUTOTUNE   = tf.data.AUTOTUNE\n",
                "EPOCHS_TOP = 200   # 先訓練頂層\n",
                "\n",
                "# ========== 1. 蒐集檔名 (排除 _mask.png) & 分層切分 ==========\n",
                "class_names = sorted([p.name for p in DATA_DIR.iterdir() if p.is_dir()])\n",
                "\n",
                "filepaths, labels = [], []\n",
                "for cls_idx, cls_name in enumerate(class_names):\n",
                "    for img_path in (DATA_DIR / cls_name).glob(\"*.png\"):\n",
                "        if \"_mask\" in img_path.stem:          # ★ 排除 segmentation mask\n",
                "            continue\n",
                "        filepaths.append(str(img_path))\n",
                "        labels.append(cls_idx)\n",
                "\n",
                "filepaths, labels = np.array(filepaths), np.array(labels)\n",
                "\n",
                "train_idx, val_idx = train_test_split(\n",
                "    np.arange(len(labels)),\n",
                "    test_size=0.2,\n",
                "    stratify=labels,\n",
                "    random_state=42,\n",
                ")\n",
                "\n",
                "train_paths, val_paths = filepaths[train_idx], filepaths[val_idx]\n",
                "train_labels, val_labels = labels[train_idx],  labels[val_idx]\n",
                "\n",
                "# ========== 2. tf.data pipeline ==========\n",
                "def load_and_prep(path, label):\n",
                "    img = tf.io.read_file(path)\n",
                "    img = tf.image.decode_png(img, channels=3)          # BUSI 為灰階，但轉 3ch 便於載權重\n",
                "    img = tf.image.resize(img, IMG_SIZE)\n",
                "    img = preprocess_input(img)                         # ★ 用官方前處理\n",
                "    return img, label\n",
                "\n",
                "augmenter = tf.keras.Sequential([\n",
                "    layers.RandomFlip(\"horizontal\"),\n",
                "    layers.RandomRotation(0.2),\n",
                "    layers.RandomZoom(0.1),\n",
                "    layers.RandomContrast(0.2),\n",
                "    layers.RandomBrightness(0.1),\n",
                "])\n",
                "\n",
                "def make_dataset(paths, labels, training=False):\n",
                "    ds = tf.data.Dataset.from_tensor_slices((paths, labels))\n",
                "    if training:\n",
                "        ds = ds.shuffle(1000)\n",
                "    ds = ds.map(load_and_prep, num_parallel_calls=AUTOTUNE)\n",
                "    if training:\n",
                "        ds = ds.map(lambda x, y: (augmenter(x, training=True), y),\n",
                "                    num_parallel_calls=AUTOTUNE)\n",
                "    return ds.batch(BATCH_SIZE).prefetch(AUTOTUNE)\n",
                "\n",
                "train_ds = make_dataset(train_paths, train_labels, training=True)\n",
                "val_ds   = make_dataset(val_paths,   val_labels,   training=False)\n",
                "\n",
                "# ========== 3. 類別權重 ==========\n",
                "cw = class_weight.compute_class_weight(\n",
                "    class_weight=\"balanced\",\n",
                "    classes=np.unique(train_labels),\n",
                "    y=train_labels,\n",
                ")\n",
                "class_weight_dict = dict(enumerate(cw))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "abffd9ee",
            "metadata": {
                "colab": {
                    "base_uri": "https://localhost:8080/"
                },
                "id": "abffd9ee",
                "outputId": "c3d44dd8-02b8-4a08-882e-19257177451c"
            },
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Downloading data from https://storage.googleapis.com/keras-applications/efficientnetb0_notop.h5\n",
                        "\u001b[1m16705208/16705208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
                        "Epoch 1/200\n",
                        "\u001b[1m18/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 656ms/step - accuracy: 0.3292 - loss: 1.1653"
                    ]
                }
            ],
            "source": [
                "import tensorflow as tf\n",
                "from tensorflow.keras import layers\n",
                "from tensorflow.keras.applications.efficientnet import (\n",
                "    EfficientNetB0, preprocess_input,\n",
                ")\n",
                "from sklearn.model_selection import train_test_split\n",
                "from sklearn.utils import class_weight\n",
                "import numpy as np\n",
                "from pathlib import Path\n",
                "import matplotlib.pyplot as plt\n",
                "\n",
                "\n",
                "# ========== 4. 建立模型：EfficientNetB0 ==========\n",
                "base = EfficientNetB0(\n",
                "    include_top=False,\n",
                "    input_shape=IMG_SIZE + (3,),\n",
                "    weights=\"imagenet\",\n",
                ")\n",
                "base.trainable = True               # 先凍結特徵抽取器\n",
                "\n",
                "inputs  = tf.keras.Input(shape=IMG_SIZE + (3,))\n",
                "x = base(inputs, training=False)\n",
                "x = layers.GlobalAveragePooling2D()(x)\n",
                "x = layers.Dropout(0.3)(x)\n",
                "outputs = layers.Dense(len(class_names), activation=\"softmax\")(x)\n",
                "\n",
                "model = tf.keras.Model(inputs, outputs)\n",
                "model.compile(\n",
                "    optimizer=tf.keras.optimizers.Adam(1e-5),\n",
                "    loss=\"sparse_categorical_crossentropy\",\n",
                "    metrics=[\"accuracy\"],\n",
                ")\n",
                "\n",
                "# ========== 5. 訓練頂層 ==========\n",
                "history_top = model.fit(\n",
                "    train_ds,\n",
                "    validation_data=val_ds,\n",
                "    epochs=EPOCHS_TOP,\n",
                "    class_weight=class_weight_dict,\n",
                "    callbacks=[\n",
                "        tf.keras.callbacks.EarlyStopping(\n",
                "            monitor=\"val_loss\", patience=3, restore_best_weights=True\n",
                "        ),\n",
                "        tf.keras.callbacks.ReduceLROnPlateau(\n",
                "            monitor=\"val_loss\", factor=0.3, patience=2\n",
                "        ),\n",
                "    ],\n",
                ")\n",
                "\n",
                "plot_history(history_top,  \"(EfficientNetB0)\")\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "570efb3d",
            "metadata": {
                "id": "570efb3d"
            },
            "outputs": [],
            "source": [
                "# --- ResNet50 模型訓練 ---\n",
                "from tensorflow.keras.applications import ResNet50\n",
                "from tensorflow.keras.applications.resnet import preprocess_input as resnet_preprocess\n",
                "from tensorflow.keras.models import Model\n",
                "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Input\n",
                "\n",
                "# 使用 ResNet50，不包含頂層分類器\n",
                "base_model = ResNet50(weights=\"imagenet\", include_top=False, input_tensor=Input(shape=IMG_SIZE + (3,)))\n",
                "base_model.trainable = False  # 先凍結特徵提取層\n",
                "\n",
                "# 加上分類頭\n",
                "x = base_model.output\n",
                "x = GlobalAveragePooling2D()(x)\n",
                "output = Dense(len(class_names), activation=\"softmax\")(x)\n",
                "model_resnet = Model(inputs=base_model.input, outputs=output)\n",
                "\n",
                "# 編譯模型\n",
                "model_resnet.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
                "\n",
                "# 資料前處理（根據 ResNet 要求）\n",
                "train_ds_resnet = train_ds.map(lambda x, y: (resnet_preprocess(x), y))\n",
                "val_ds_resnet = val_ds.map(lambda x, y: (resnet_preprocess(x), y))\n",
                "\n",
                "# 訓練模型\n",
                "history_resnet = model_resnet.fit(\n",
                "    train_ds_resnet,\n",
                "    validation_data=val_ds_resnet,\n",
                "    epochs=EPOCHS_TOP,\n",
                "    callbacks=[\n",
                "        tf.keras.callbacks.EarlyStopping(\n",
                "            monitor=\"val_loss\", patience=3, restore_best_weights=True\n",
                "        ),\n",
                "        tf.keras.callbacks.ReduceLROnPlateau(\n",
                "            monitor=\"val_loss\", factor=0.3, patience=2\n",
                "        ),])\n",
                "\n",
                "plot_history(history_resnet, title_suffix=\"(ResNet50)\")\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "6f0f6a0f",
            "metadata": {
                "id": "6f0f6a0f"
            },
            "outputs": [],
            "source": [
                "# --- DenseNet121 模型訓練 ---\n",
                "from tensorflow.keras.applications import DenseNet121\n",
                "from tensorflow.keras.applications.densenet import preprocess_input as densenet_preprocess\n",
                "\n",
                "# 使用 DenseNet121，不包含頂層分類器\n",
                "base_model = DenseNet121(weights=\"imagenet\", include_top=False, input_tensor=Input(shape=IMG_SIZE + (3,)))\n",
                "base_model.trainable = False\n",
                "\n",
                "# 加上分類頭\n",
                "x = base_model.output\n",
                "x = GlobalAveragePooling2D()(x)\n",
                "output = Dense(len(class_names), activation=\"softmax\")(x)\n",
                "model_densenet = Model(inputs=base_model.input, outputs=output)\n",
                "\n",
                "# 編譯模型\n",
                "model_densenet.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
                "\n",
                "# 資料前處理（根據 DenseNet 要求）\n",
                "train_ds_dense = train_ds.map(lambda x, y: (densenet_preprocess(x), y))\n",
                "val_ds_dense = val_ds.map(lambda x, y: (densenet_preprocess(x), y))\n",
                "\n",
                "# 訓練模型\n",
                "history_densenet = model_densenet.fit(\n",
                "    train_ds_dense,\n",
                "    validation_data=val_ds_dense,\n",
                "    epochs=EPOCHS_TOP,\n",
                "    callbacks=[\n",
                "        tf.keras.callbacks.EarlyStopping(\n",
                "            monitor=\"val_loss\", patience=3, restore_best_weights=True\n",
                "        ),\n",
                "        tf.keras.callbacks.ReduceLROnPlateau(\n",
                "            monitor=\"val_loss\", factor=0.3, patience=2\n",
                "        ),]\n",
                "    )\n",
                "\n",
                "plot_history(history_densenet, title_suffix=\"(DenseNet121)\")"
            ]
        }
    ],
    "metadata": {
        "accelerator": "GPU",
        "colab": {
            "gpuType": "T4",
            "provenance": []
        },
        "kernelspec": {
            "display_name": ".venv",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.12.9"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}